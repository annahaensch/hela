{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Hela ML libraries \n",
    "from hela import hmm\n",
    "import hela.generation.hmm as hmm_gen\n",
    "\n",
    "# Viz libraries\n",
    "import altair as alt\n",
    "import hela.visualization.hmm as hmmplot \n",
    "import matplotlib.pyplot as plt\n",
    "from hela.visualization.hmm import TU_COLORS\n",
    "%matplotlib inline\n",
    "\n",
    "# Utility Libraries\n",
    "from datetime import datetime\n",
    "from dask.distributed import Client\n",
    "from scipy.special import logsumexp\n",
    "from scipy import stats\n",
    "import itertools\n",
    "from IPython.display import Image\n",
    "\n",
    "# PGMPy\n",
    "from hela.hmm.graphical_models import DynamicBayesianNetwork as dbn\n",
    "from hela.hmm.graphical_models.ContinuousFactor import ContinuousFactor\n",
    "# from pgmpy.factors.discrete import TabularCPD\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "generative_model = hmm_gen.DiscreteHMMGenerativeModel(\n",
    "                                     n_hidden_states = 3,\n",
    "                                     n_gaussian_features=0,\n",
    "                                    n_categorical_features = 2,\n",
    "                                     n_gmm_components = None)\n",
    "\n",
    "hidden_states = generative_model.generate_hidden_state_sequence(n_observations = n)\n",
    "hmm_data = generative_model.generate_observations(hidden_states)\n",
    "hmm_training_spec = generative_model.generative_model_to_discrete_hmm_training_spec()\n",
    "model_config = hmm.DiscreteHMMConfiguration.from_spec(hmm_training_spec)\n",
    "model = model_config.to_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dbn.hmm_model_to_graph(model)\n",
    "graph.initialize_initial_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[0, 0]': 0, '[0, 1]': 1, '[0, 2]': 2, '[1, 0]': 3, '[1, 1]': 4, '[1, 2]': 5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_dict = {\n",
    "    str(list(model.categorical_model.finite_values.values[i])): i\n",
    "    for i in range(len(model.categorical_model.finite_values))\n",
    "}\n",
    "categorical_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_flattened_data = pd.Series(\n",
    "            [categorical_dict[str(list(v))] for v in np.array(hmm_data)],\n",
    "            index=hmm_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_keys = [('cat_obs', i) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_dict = dict(zip(ev_keys, hmm_flattened_data.values[:n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [('hs', i) for i in range(1,n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import tee, chain, combinations\n",
    "\n",
    "from pgmpy.factors.discrete import DiscreteFactor\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.factors import factor_product\n",
    "from pgmpy.inference import Inference, BeliefPropagation\n",
    "from hela.hmm.graphical_models import structured_inference as dbn_inf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for ('hs', 1)\n"
     ]
    }
   ],
   "source": [
    "inference = dbn_inf.DBNInference(graph)\n",
    "inference.interface_nodes_0 = graph.get_interface_nodes(time_slice=0)\n",
    "inference.interface_nodes_1 = graph.get_interface_nodes(time_slice=1)\n",
    "inference.start_bayesian_model = BayesianModel(graph.get_intra_edges(0))\n",
    "flattened_factors_0 = [cpd[0] for cpd in graph.get_factors(time_slice=0)]\n",
    "flattened_factors_1 = [cpd[0] for cpd in graph.get_factors(time_slice=1)]\n",
    "inference.start_bayesian_model.add_cpds(*flattened_factors_0)\n",
    "cpd_inter = [graph.get_factors(node)[0] for node in graph.get_interface_nodes(1)]\n",
    "inference.interface_nodes = graph.get_interface_nodes(0)\n",
    "inference.one_and_half_model = BayesianModel(\n",
    "    graph.get_inter_edges() + graph.get_intra_edges(1)\n",
    ")\n",
    "\n",
    "inference.one_and_half_model.add_cpds(\n",
    "    *(flattened_factors_1 + cpd_inter)\n",
    ")\n",
    "start_markov_model = inference.start_bayesian_model.to_markov_model()\n",
    "one_and_half_markov_model = inference.one_and_half_model.to_markov_model()\n",
    "combinations_slice_0 = tee(combinations(inference.interface_nodes_0, 2), 2)\n",
    "combinations_slice_1 = combinations(inference.interface_nodes_1, 2)\n",
    "start_markov_model.add_edges_from(combinations_slice_0[0])\n",
    "one_and_half_markov_model.add_edges_from(\n",
    "    chain(combinations_slice_0[1], combinations_slice_1)\n",
    ")\n",
    "\n",
    "inference.one_and_half_junction_tree = one_and_half_markov_model.to_junction_tree()\n",
    "inference.start_junction_tree = start_markov_model.to_junction_tree()\n",
    "\n",
    "inference.start_interface_clique = inference._get_clique(\n",
    "    inference.start_junction_tree, inference.interface_nodes_0\n",
    ")\n",
    "inference.in_clique = inference._get_clique(\n",
    "    inference.one_and_half_junction_tree, inference.interface_nodes_0\n",
    ")\n",
    "inference.out_clique = inference._get_clique(\n",
    "    inference.one_and_half_junction_tree, inference.interface_nodes_1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeView([(('hs', 0), ('hs', 1)), (('hs', 1), ('cat_obs', 1))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_and_half_markov_model.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView((('hs', 0), ('hs', 1), ('cat_obs', 1)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_and_half_markov_model.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeView([((('hs', 1), ('hs', 0)), (('hs', 1), ('cat_obs', 1)))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference.one_and_half_junction_tree.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98442657, 0.01557343, 0.        ],\n",
       "       [0.        , 0.98579456, 0.01420544],\n",
       "       [0.01527483, 0.        , 0.98472517]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference.one_and_half_junction_tree.factors[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DiscreteFactor representing phi(('hs', 1):3, ('hs', 0):3) at 0x7febb34856a0>,\n",
       " <DiscreteFactor representing phi(('hs', 1):3, ('cat_obs', 1):6) at 0x7febb3485550>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference.one_and_half_junction_tree.factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.92394114e-02, 7.67759015e-01, 4.86698534e-02, 3.25128510e-02,\n",
       "        3.49195038e-02, 5.68993659e-02],\n",
       "       [9.49789641e-01, 2.91747775e-04, 1.20145520e-02, 1.12286595e-02,\n",
       "        1.25541161e-02, 1.41212836e-02],\n",
       "       [2.57349237e-02, 4.35271010e-02, 6.59570844e-03, 3.56859266e-02,\n",
       "        7.99425980e-03, 8.80462080e-01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.factors[-1].values.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EdgeView([((('hs', 1), ('cat_obs', 1)), (('hs', 1), ('hs', 0)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hs', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(('hs', 1), ('cat_obs', 1))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junction_tree = inference.one_and_half_junction_tree\n",
    "nodes = inference.interface_nodes_1\n",
    "print(nodes)\n",
    "[clique for clique in junction_tree.nodes() if set(nodes).issubset(clique) and clique[0][1] == clique[1][1]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('hs', 1), ('cat_obs', 1))\n"
     ]
    }
   ],
   "source": [
    "cliques = [clique for clique in junction_tree.nodes() if set(nodes).issubset(clique)]\n",
    "print([clique for clique in cliques if clique[0][1] == clique[1][1]][0])\n",
    "# [[(nodes[1], nodes[1]) for nodes in clique if nodes[0] == nodes[0]] for clique in cliques]\n",
    "# for clique in cliques:\n",
    "#     print(clique[0][1] == clique[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('hs', 1), ('hs', 0))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junction_tree = inference.one_and_half_junction_tree\n",
    "nodes = inference.interface_nodes_0\n",
    "[clique for clique in junction_tree.nodes() if set(nodes).issubset(clique)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('hs', 1), ('hs', 0))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference.out_clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('hs', 1), ('hs', 0)), (('hs', 1), ('cat_obs', 1))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_and_half_markov_model.check_model()\n",
    "\n",
    "# Triangulate the graph to make it chordal\n",
    "triangulated_graph = one_and_half_markov_model.triangulate()\n",
    "cliques = list(map(tuple, nx.find_cliques(triangulated_graph)))\n",
    "cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cliques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('hs', 1), ('hs', 0)], [('hs', 1), ('cat_obs', 1)]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nx.find_cliques(triangulated_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((('hs', 1), ('hs', 0)), (('hs', 1), ('cat_obs', 1)))\n"
     ]
    }
   ],
   "source": [
    "edges = list(itertools.combinations(cliques, 2))\n",
    "edges\n",
    "for edge in edges:\n",
    "    print(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find maximal cliques in the chordal graph\n",
    "# cliques = list(map(tuple, nx.find_cliques(triangulated_graph)))\n",
    "\n",
    "# # If there is only 1 clique, then the junction tree formed is just a\n",
    "# # clique tree with that single clique as the node\n",
    "# if len(cliques) == 1:\n",
    "#     clique_trees = JunctionTree()\n",
    "#     clique_trees.add_node(cliques[0])\n",
    "\n",
    "# # Else if the number of cliques is more than 1 then create a complete\n",
    "# # graph with all the cliques as nodes and weight of the edges being\n",
    "# # the length of sepset between two cliques\n",
    "# elif len(cliques) >= 2:\n",
    "#     complete_graph = UndirectedGraph()\n",
    "#     edges = list(itertools.combinations(cliques, 2))\n",
    "#     weights = list(map(lambda x: len(set(x[0]).intersection(set(x[1]))), edges))\n",
    "#     for edge, weight in zip(edges, weights):\n",
    "#         complete_graph.add_edge(*edge, weight=-weight)\n",
    "\n",
    "#     # Create clique trees by minimum (or maximum) spanning tree method\n",
    "#     clique_trees = JunctionTree(\n",
    "#         nx.minimum_spanning_tree(complete_graph).edges()\n",
    "#     )\n",
    "\n",
    "# # Check whether the factors are defined for all the random variables or not\n",
    "# all_vars = itertools.chain(*[factor.scope() for factor in self.factors])\n",
    "# if set(all_vars) != set(self.nodes()):\n",
    "#     ValueError(\"DiscreteFactor for all the random variables not specified\")\n",
    "\n",
    "# # Dictionary stating whether the factor is used to create clique\n",
    "# # potential or not\n",
    "# # If false, then it is not used to create any clique potential\n",
    "# is_used = {factor: False for factor in self.factors}\n",
    "\n",
    "# for node in clique_trees.nodes():\n",
    "#     clique_factors = []\n",
    "#     for factor in self.factors:\n",
    "#         # If the factor is not used in creating any clique potential as\n",
    "#         # well as has any variable of the given clique in its scope,\n",
    "#         # then use it in creating clique potential\n",
    "#         if not is_used[factor] and set(factor.scope()).issubset(node):\n",
    "#             clique_factors.append(factor)\n",
    "#             is_used[factor] = True\n",
    "\n",
    "#     # To compute clique potential, initially set it as unity factor\n",
    "#     var_card = [self.get_cardinality()[x] for x in node]\n",
    "#     clique_potential = DiscreteFactor(\n",
    "#         node, var_card, np.ones(np.product(var_card))\n",
    "#     )\n",
    "#     # multiply it with the factors associated with the variables present\n",
    "#     # in the clique (or node)\n",
    "#     # Checking if there's clique_factors, to handle the case when clique_factors\n",
    "#     # is empty, otherwise factor_product with throw an error [ref #889]\n",
    "#     if clique_factors:\n",
    "#         clique_potential *= factor_product(*clique_factors)\n",
    "#     clique_trees.add_factors(clique_potential)\n",
    "\n",
    "# if not all(is_used.values()):\n",
    "#     raise ValueError(\n",
    "#         \"All the factors were not used to create Junction Tree.\"\n",
    "#         \"Extra factors are defined.\"\n",
    "#     )\n",
    "\n",
    "# return clique_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
