{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Hela ML libraries \n",
    "from hela import hmm\n",
    "import hela.generation.hmm as hmm_gen\n",
    "\n",
    "# Viz libraries\n",
    "import altair as alt\n",
    "import hela.visualization.hmm as hmmplot \n",
    "import matplotlib.pyplot as plt\n",
    "from hela.visualization.hmm import TU_COLORS\n",
    "%matplotlib inline\n",
    "\n",
    "# Utility Libraries\n",
    "from datetime import datetime\n",
    "from dask.distributed import Client\n",
    "from scipy.special import logsumexp\n",
    "from scipy import stats\n",
    "import itertools\n",
    "from IPython.display import Image\n",
    "\n",
    "# PGMPy\n",
    "from hela.hmm.graphical_models import DynamicBayesianNetwork as dbn\n",
    "# from hela.hmm.graphical_models import structured_inference as dbn_inf\n",
    "from pgmpy.inference import dbn_inference as dbn_inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "generative_model = hmm_gen.DiscreteHMMGenerativeModel(\n",
    "                                     n_hidden_states = 3,\n",
    "                                     n_gaussian_features=0,\n",
    "                                    n_categorical_features = 2,\n",
    "                                     n_gmm_components = None)\n",
    "\n",
    "hidden_states = generative_model.generate_hidden_state_sequence(n_observations = n)\n",
    "\n",
    "hmm_data = generative_model.generate_observations(hidden_states)\n",
    "hmm_training_spec = generative_model.generative_model_to_discrete_hmm_training_spec()\n",
    "model_config = hmm.DiscreteHMMConfiguration.from_spec(hmm_training_spec)\n",
    "hmm_model = model_config.to_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PGMpy Structure of HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HMM_graph](hmm_graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = dbn.hmm_model_to_graph(hmm_model)\n",
    "# graph.initialize_initial_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_graph = dbn.hmm_model_to_graph(hmm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[0, 0]': 0, '[0, 1]': 1, '[0, 2]': 2, '[1, 0]': 3, '[1, 1]': 4, '[1, 2]': 5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_dict = {\n",
    "    str(list(hmm_model.categorical_model.finite_values.values[i])): i\n",
    "    for i in range(len(hmm_model.categorical_model.finite_values))\n",
    "}\n",
    "categorical_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_flattened_data = pd.Series(\n",
    "            [categorical_dict[str(list(v))] for v in np.array(hmm_data)],\n",
    "            index=hmm_data.index)\n",
    "\n",
    "ev_keys = [('cat_obs', i) for i in range(n)]\n",
    "ev_dict = dict(zip(ev_keys, hmm_flattened_data.values[:n]))\n",
    "variables = [('hs', i) for i in range(2,n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM Graphical Inference\n",
    "\n",
    "Inference in the graphical HMM model is done by belief propagation with variable elimination. In the case of graphs with HMM structure, this becomes equivalent to the forward-backward algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DBNInference' object has no attribute 'start_bayesian_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f1ec1a2f4ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbn_inf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDBNInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mev_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mev_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pgmpy/inference/dbn_inference.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface_nodes_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_interface_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_slice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mstart_markov_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_bayesian_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_markov_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mone_and_half_markov_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_and_half_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_markov_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DBNInference' object has no attribute 'start_bayesian_model'"
     ]
    }
   ],
   "source": [
    "inference = dbn_inf.DBNInference(hmm_graph)\n",
    "forward = inference.forward_inference(variables, ev_dict)\n",
    "backward = inference.backward_inference(variables, ev_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = [(forward[key]*backward[key]).values for key in forward]\n",
    "\n",
    "posterior = np.divide(np.array(posterior), np.sum(np.array(posterior), axis=1).reshape(-1, 1))\n",
    "pred_hidden_states = pd.Series(\n",
    "            np.argmax(posterior, axis = 1),\n",
    "            index=hidden_states.index[2:n])\n",
    "\n",
    "hmmplot.draw_states(pred_hidden_states, hide_brush=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmmplot.draw_states(hidden_states[2:n], hide_brush=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHMM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = hmm_gen.FactoredHMMGenerativeModel(\n",
    "                                     ns_hidden_states =[2, 2, 2],\n",
    "                                     n_gaussian_features = 0,\n",
    "                                     n_categorical_features = 2)\n",
    "\n",
    "factored_hidden_states = gen.generate_hidden_state_sequence(n_observations = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_hidden_states = gen.flatten_hidden_state_sequence(factored_hidden_states)\n",
    "hmmplot.draw_states(flattened_hidden_states, hide_brush=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhmm_data = gen.generate_observations(factored_hidden_states)\n",
    "fhmm_training_spec = hmm_gen.data_to_fhmm_training_spec(factored_hidden_states, \n",
    "                                   gen.ns_hidden_states, \n",
    "                                   fhmm_data,\n",
    "                                   categorical_features = list(gen.categorical_values.columns), \n",
    "                                   gaussian_features = [])\n",
    "\n",
    "fhmm_config = hmm.FactoredHMMConfiguration.from_spec(fhmm_training_spec)\n",
    "\n",
    "fhmm_model = fhmm_config.to_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhmm_model.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PGMpy Structure of FHMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the edge factors in an FHMM graph, each transition arrow is defined by the corresponding transition matrix for that system.  For categorical data, we define the marginalized emission probability for each emission edge.  For continous data, the edge is defined by the W matrix and covariance matrix.  In the learning/inference process these will be used to generate the pdf for a given hs vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in fhmm_model.graph.nodes:\n",
    "    print(\"latent status for node {} at time step {}: \".format(node[0], node[1]), \n",
    "          fhmm_model.graph.nodes[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhmm_model.graph.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhmm_model.graph.check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhmm_model.graph.get_factors(time_slice=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhmm_model.graph.get_factors(time_slice=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhmm_model.graph.edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Variational Inference\n",
    "\n",
    "We break up each of the Markov systems in the fHMM graph and run the forward backward algorithm in each of the systems\n",
    "\n",
    "\n",
    "TODO: add in variational parameter + checking for convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_graphs = fhmm_model.graph.generate_system_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in system_graphs:\n",
    "    assert graph.check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_graphs[0].factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_graphs[1].factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_graphs[2].factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, graph in enumerate(system_graphs):\n",
    "    print(\"Nodes present in chain {}: {} \".format(i, graph.nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "categorical_dict = {\n",
    "    str(list(fhmm_model.categorical_model.categorical_values.values[i])): i\n",
    "    for i in range(len(fhmm_model.categorical_model.categorical_values))\n",
    "}\n",
    "\n",
    "fhmm_flattened_data = pd.Series(\n",
    "            [categorical_dict[str(list(v))] for v in np.array(fhmm_data)],\n",
    "            index=fhmm_data.index)\n",
    "\n",
    "system = system_graphs[0].get_latent_nodes()[0][0]\n",
    "observation_node = system_graphs[0].get_observable_nodes()[0][0]\n",
    "\n",
    "ev_keys = [(observation_node, i) for i in range(n)]\n",
    "ev_dict = dict(zip(ev_keys, fhmm_flattened_data.values[:n]))\n",
    "variables = [(system, i) for i in range(2,n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = dbn_inf.DBNInference(system_graphs[0])\n",
    "forward = inference.forward_inference(variables, ev_dict)\n",
    "backward = inference.backward_inference(variables, ev_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = [(forward[key]*backward[key]).values for key in forward]\n",
    "\n",
    "posterior = np.divide(np.array(posterior), np.sum(np.array(posterior), axis=1).reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[forward[key].values for key in forward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[backward[key].values for key in backward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
